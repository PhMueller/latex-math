% machine learning


%%%%%% ml - data
\newcommand{\Xspace}{\mathcal{X}}                                           % X, input space
\newcommand{\Yspace}{\mathcal{Y}}                                           % Y, output space
\newcommand{\nset}{\{1, \ldots, n\}}                                        % set from 1 to n
\newcommand{\pset}{\{1, \ldots, p\}}                                        % set from 1 to p
\newcommand{\gset}{\{1, \ldots, g\}}                                        % set from 1 to g
\newcommand{\Pxy}{\P_{xy}}                                                  % P_xy
\newcommand{\Exy}{\mathbb{E}_{xy}}                                          % E_xy: Expectation over random variables xy
\newcommand{\xy}{(\xb, y)}                                                  % observation (x, y)
\newcommand{\xvec}{\left(x_1, \ldots, x_p\right)^T}                         % (x1, ..., xp) 
\newcommand{\xb}{\mathbf{x}}												  % x (bold) feature vector
\newcommand{\Xmat}{\mathbf{X}}											  % Design matrix
\newcommand{\D}{\mathcal{D}}                                                % D, data 
\newcommand{\Dset}{\left\{ \left(\xb^{(1)}, y^{(1)}\right), \ldots, \left(\xb^{(n)},  y^{(n)}\right)\right\}}    % {(x1,y1)), ..., (xn,yn)}, data
\newcommand{\xdat}{\left\{ \xb^{(1)}, \ldots, \xb^{(n)}\right\}}   				% {x1, ..., xn}, input data
\newcommand{\ydat}{\mathbf{y}}                                              % y (bold), vector of outcomes
\newcommand{\yvec}{\left(y^{(1)}, \hdots, y^{(n)}\right)^T}                 % (y1, ..., yn), vector of outcomes
\renewcommand{\xi}[1][i]{\xb^{(#1)}}                                          % x^i, i-th observed value of x
\newcommand{\yi}[1][i]{y^{(#1)}}                                            % y^i, i-th observed value of y 
\newcommand{\xyi}[1][i]{\left(\xb^{(#1)}, y^{(#1)}\right)}                                    % (x^i, y^i), i-th observation
\newcommand{\xivec}{\left(x^{(i)}_1, \ldots, x^{(i)}_p\right)^T}            % (x1^i, ..., xp^i), i-th observation vector
\newcommand{\xj}{x_j}                                                       % x_j, j-th feature
\newcommand{\xjb}{\mathbf{x}_j}                                             % x_j (bold), j-th feature vecor
\newcommand{\xjvec}{\left(x^{(1)}_j, \ldots, x^{(n)}_j\right)^T}            % (x^1_j, ..., x^n_j), j-th feature vector
\newcommand{\Dtrain}{\mathcal{D}_{\text{train}}}                            % D_train, training set
\newcommand{\Dtest}{\mathcal{D}_{\text{test}}}                              % D_test, test set
\newcommand{\phiv}{\mathbf{\phi}}												% Basis transformation function phi
\newcommand{\phixi}{\mathbf{\phi}^{(i)}}										% Basis transformation of xi: phi^i := phi(xi)

%%%%%% ml - models general

% Inducer / Inducing algorithm
\newcommand{\inducer}{\mathcal{I}}                                                % Inducer, inducing algorithm, learning algorithm 

% continuous prediction function f
\newcommand{\ftrue}{f_{\text{true}}}										  % True underlying function (if a statistical model is assumed)
\newcommand{\ftruex}{\ftrue(\xb)}										  % True underlying function (if a statistical model is assumed)
\newcommand{\fx}{f(\xb)}                                                      % f(x), continuous prediction function
\newcommand{\Hspace}{\mathcal{H}}														% hypothesis space where f is from
\newcommand{\fh}{\hat{f}}                                                   % f hat, estimated prediction function
\newcommand{\fxh}{\fh(\xb)}                                                   % fhat(x)
\newcommand{\fxt}{f(\xb ~|~ \thetab)}                                            % f(x | theta)
\newcommand{\fxi}{f\left(\xi\right)}                                        % f(x^(i))
\newcommand{\fxih}{\hat{f}\left(\xi\right)}                                 % f(x^(i))
\newcommand{\fxit}{f\left(\xi ~|~ \thetab\right)}                          % f(x^(i) | theta)
\newcommand{\fhD}{\fh_{\D}}                                                 % fhat_D, estimate of f based on D
\newcommand{\fhDtrain}{\fh_{\Dtrain}}                                       % fhat_Dtrain, estimate of f based on D


% discrete prediction function h
\newcommand{\hx}{h(\xb)}                                                      % h(x), discrete prediction function
\newcommand{\hxv}{h(\xv)}                                                      % h(x), discrete prediction function with x (vector) as input
\newcommand{\hh}{\hat{h}}                                                   % h hat
\newcommand{\hxh}{\hat{h}(\xb)}                                               % hhat(x)
\newcommand{\hxt}{h(\xb | \thetab)}                                            % h(x | theta)
\newcommand{\hxi}{h\left(\xi\right)}                                        % h(x^(i))
\newcommand{\hxit}{h\left(\xi ~|~ \thetab\right)}                          % h(x^(i) | theta)

% yhat
\newcommand{\yh}{\hat{y}}                                                   % yhat for prediction of target
\newcommand{\yih}{\hat{y}^{(i)}}                                            % yhat^(i) for prediction of ith targiet

% theta
\newcommand{\thetah}{\bm{\hat{\thetab}}}                                          % theta hat
\newcommand{\thetab}{\bm{\theta}}											% theta vector
\newcommand{\thetabh}{\bm{\hat\theta}}											% theta vector

% densities + probabilities
% pdf of x 
\newcommand{\pdf}{p}                                                        % p
\newcommand{\pdfx}{p(x)}                                                    % p(x)
\newcommand{\pixt}{\pi(\xb~|~ \thetab)}                                         % pi(x|theta), pdf of x given theta
\newcommand{\pixit}{\pi\left(\xi ~|~ \thetab\right)}                           % pi(x^i|theta), pdf of x given theta

% pdf of (x, y)
\newcommand{\pdfxy}{p(\xb,y)}                                                 % p(x, y)
\newcommand{\pdfxyt}{p(\xb, y ~|~ \thetab)}                                      % p(x, y | theta)
\newcommand{\pdfxyit}{p\left(\xi, \yi ~|~ \thetab\right)}                      % p(x^(i), y^(i) | theta)

% pdf of x given y
\newcommand{\pdfxyk}{p(x | y=k)}                                            % p(x | y = k)
\newcommand{\lpdfxyk}{\log \pdfxyk}                                         % log p(x | y = k)
\newcommand{\pdfxiyk}{p\left(\xi | y=k\right)}                              % p(x^i | y = k)

% prior probabilities
\newcommand{\pik}{\pi_k}                                                    % pi_k, prior
\newcommand{\lpik}{\log \pik}                                               % log pi_k, log of the prior
\newcommand{\pit}{\pi(\thetab)}												% Prior probability of parameter theta

% posterior probabilities
\newcommand{\post}{\P(y = 1 ~|~ \xb)}                                           % P(y = 1 | x), post. prob for y=1
\newcommand{\pix}{\pi(\xb)}                                                   % pi(x), P(y = 1 | x)
\newcommand{\postk}{\P(y = k ~|~ \xb)}                                          % P(y = k | y), post. prob for y=k
\newcommand{\pikx}{\pi_k(\xb)}                                                % pi_k(x), P(y = k | x)
\newcommand{\pikxt}{\pi_k(\xb ~|~ \thetab)}                                      % pi_k(x | theta), P(y = k | x, theta)
\newcommand{\pijx}{\pi_j(\xb)}                                                % pi_j(x), P(y = j | x)
\newcommand{\pdfygxt}{p(y ~|~\xb, \thetab)}                                      % p(y | x, theta)
\newcommand{\pdfyigxit}{p\left(\yi ~|~\xi, \thetab\right)}                     % p(y^i |x^i, theta)
\newcommand{\lpdfygxt}{\log \pdfygxt }                                      % log p(y | x, theta)
\newcommand{\lpdfyigxit}{\log \pdfyigxit}                                   % log p(y^i |x^i, theta)
\newcommand{\pixh}{\hat \pi(\xb)}                                             % pi(x) hat, P(y = 1 | x) hat
\newcommand{\pikxh}{\hat \pi_k(\xb)}                                          % pi_k(x) hat, P(y = k | x) hat
\newcommand{\pixih}{\hat \pi(\xi)}                                      % pi(x^(i)) with hat
\newcommand{\pikxih}{\hat \pi_k(\xi)}                                   % pi_k(x^(i)) with hat

% residual and margin
\newcommand{\eps}{\epsilon}                                                 % residual, stochastic
\newcommand{\epsi}{\epsilon^{(i)}}                                          % epsilon^i, residual, stochastic
\newcommand{\epsh}{\hat{\epsilon}}                                          % residual, estimated
\newcommand{\yf}{y \fx}                                                     % y f(x), margin
\newcommand{\yfi}{\yi \fxi}                                                 % y^i f(x^i), margin
\newcommand{\Sigmah}{\hat \Sigma}											% estimated covariance matrix
\newcommand{\Sigmahj}{\hat \Sigma_j}										% estimated covariance matrix for the j-th class

% ml - loss, risk, likelihood
\newcommand{\Lxy}{L(y, \fx)}                                               % L(y, f(x)), loss function
\newcommand{\Lxyi}{L\left(\yi, \fxi\right)}                                 % L(y^i, f(x^i))
\newcommand{\Lxyt}{L\left(y, \fxt\right)}                                   % L(y, f(x | theta))
\newcommand{\Lxyit}{L\left(\yi, \fxit\right)}                               % L(y^i, f(x^i | theta)
\newcommand{\Lxym}{L(\yi, f(\bm{\tilde{x}}^{(i)} ~|~ \thetab))}                      % L(y^i, f(tilde(x)^i | theta), 
\newcommand{\Lhxy}{L(y, \hx)}                                               % L(y, h(x)), loss function on discrete classes
                                                                            % a somewhat weird symbol, loss of the ith obs in a MINIBATCH
\newcommand{\risk}{\mathcal{R}}                                             % R, risk
\newcommand{\riskf}{\risk(f)}                                               % R(f), risk
\newcommand{\riskt}{\mathcal{R}(\thetab)}                                    % R(theta), risk
\newcommand{\riske}{\mathcal{R}_{\text{emp}}}                               % R_emp, empirical risk (without factor 1 / n
\newcommand{\riskeb}{\bar{\mathcal{R}}_{\text{emp}}}                          % R_emp, empirical risk with factor 1 / n
\newcommand{\riskef}{\riske(f)}                                             % R_emp(f)
\newcommand{\risket}{\mathcal{R}_{\text{emp}}(\thetab)}                      % R_emp(theta)
\newcommand{\riskr}{\mathcal{R}_{\text{reg}}}                               % R_reg, regularized risk
\newcommand{\riskrt}{\mathcal{R}_{\text{reg}}(\thetab)}                      % R_reg(theta)
\newcommand{\riskrf}{\riskr(f)}                                             % R_reg(f)
\newcommand{\riskrth}{\hat{\mathcal{R}}_{\text{reg}}(\thetab)}              % hat R_reg(theta)
\newcommand{\risketh}{\hat{\mathcal{R}}_{\text{emp}}(\thetab)}			  % hat R_emp(theta)
\newcommand{\LL}{\mathcal{L}}                                               % L, likelihood
\newcommand{\LLt}{\mathcal{L}(\thetab)}                                      % L(theta), likelihood
\renewcommand{\ll}{\ell}                                                    % l, log-likelihood
\newcommand{\llt}{\ell(\thetab)}                                             % l(theta), log-likelihood
\newcommand{\LS}{\mathfrak{L}}                                              % ????????????
\newcommand{\TS}{\mathfrak{T}}                                              % ??????????????
\newcommand{\errtrain}{\text{err}_{\text{train}}}                           % training error
\newcommand{\errtest}{\text{err}_{\text{test}}}                             % training error
\newcommand{\errexp}{\overline{\text{err}_{\text{test}}}}                   % training error




% resampling
\newcommand{\GEf}{GE\left(\fh\right)}                             		% Generalization error of a fitted model
\newcommand{\GEind}{GE_n\left(\inducer_{L, O}\right)}                             		% Generalization error of a fitted model
\newcommand{\GE}[1]{GE_n\left(\fh_{#1}\right)}                             % Generalization error GE
\newcommand{\GEh}[1]{\widehat{GE}_{#1}}                                     % Estimated train error
\newcommand{\GED}{\GE{\D}}                                                  % Generalization error GE
\newcommand{\EGEn}{EGE_n}                                                   % Generalization error GE
\newcommand{\EDn}{\E_{|D| = n}}                                             % Generalization error GE




% ml - irace
\newcommand{\costs}{\mathcal{C}} 											% costs
\newcommand{\Celite}{\theta^*} 												% elite configurations
\newcommand{\instances}{\mathcal{I}} 										% sequence of instances
\newcommand{\budget}{\mathcal{B}} 											% computational budget

% ml - ROC
\newcommand{\np}{n_{+}}                                                     % no. of positive instances
\newcommand{\nn}{n_{-}}                                                     % no. of negative instances
\newcommand{\rn}{\pi_{-}}                                                   % proportion negative instances
\newcommand{\rp}{\pi_{+}}                                                   % proportion negative instances
  % true/false pos/neg:
\newcommand{\tp}{\# \text{TP}}
\newcommand{\fap}{\# \text{FP}} %fp taken for partial derivs
\newcommand{\tn}{\# \text{TN}}
\newcommand{\fan}{\# \text{FN}} 
